{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26908,
     "status": "ok",
     "timestamp": 1659601278773,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "BfSzCObCeI2U",
    "outputId": "1fc89d89-7c98-40f8-960d-613bf5d1d5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1659601278776,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "KJ1g8KVVnQde"
   },
   "outputs": [],
   "source": [
    "root = '/content/drive/MyDrive/Ravaee/GTEX/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2438,
     "status": "ok",
     "timestamp": 1659601281189,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "mWLfSnd9dxeC"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1659601281194,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "hooQGNrzd1kG"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_channels = 1\n",
    "image_size = 128\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6970,
     "status": "ok",
     "timestamp": 1659601288148,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "hs7lsaTjnVmm"
   },
   "outputs": [],
   "source": [
    "x_train =np.load(root+'data.npy')\n",
    "x_train = x_train * 2.0 - 1.0\n",
    "c_cat_dim = 54\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 603,
     "status": "ok",
     "timestamp": 1659601291177,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "EjmugXlHd4Nq",
    "outputId": "9b8a325a-ee25-4d09-b3e0-560b0228a959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (7845, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1659601291181,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "6gSiBGIMeZ1X"
   },
   "outputs": [],
   "source": [
    "def get_discriminator_model():\n",
    "  img_input = layers.Input(shape=(128, 128, 1))\n",
    "  x = layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\",name='disc_l1')(img_input)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\")(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.GlobalMaxPooling2D()(x)\n",
    "  disc_out = layers.Dense(1, name='disc_out')(x)\n",
    "\n",
    "  d_model = keras.models.Model(img_input, disc_out, name=\"discriminator\")\n",
    "\n",
    "  q_net_out = layers.Dense(128, activation='relu', kernel_initializer='he_normal' , bias_initializer='he_normal'  )(x)\n",
    "  q_net_out = layers.Dense(c_cat_dim , activation='softmax')(q_net_out)\n",
    "  q_model = keras.models.Model(img_input, q_net_out, name='q_network')\n",
    "\n",
    "  return d_model, q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1659601291183,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "7rlFbY5wpdjT"
   },
   "outputs": [],
   "source": [
    "def get_generator_model():\n",
    "  noise = layers.Input(shape=(latent_dim,))\n",
    "  labels = layers.Input(shape=(c_cat_dim,))\n",
    "  inputs =layers.concatenate([noise,labels], axis=1)\n",
    "  x = layers.Dense(8 * 8 * (latent_dim+c_cat_dim), name='gen_l1')(inputs)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Reshape((8, 8, latent_dim+c_cat_dim))(x)\n",
    "  x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\",use_bias=False)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding=\"same\",use_bias=False)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding=\"same\",use_bias=False)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2DTranspose(128, (7, 7), strides=(2, 2), padding=\"same\",use_bias=False)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "  x = layers.Conv2D(1, (7, 7), padding=\"same\",use_bias=False)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation('tanh',name='gen_out')(x)\n",
    "  g_model = keras.models.Model([noise,labels], x, name=\"generator\")\n",
    "  return g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2158,
     "status": "ok",
     "timestamp": 1659601293328,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "neXuOJd7pYus",
    "outputId": "5673b31c-4a6a-4574-8437-6873fb6ab1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "d_model, q_network = get_discriminator_model()\n",
    "# d_model.summary()\n",
    "# d_model = tf.keras.models.load_model('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN Discriminator.h5')\n",
    "# q_network = tf.keras.models.load_model('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN q-net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1405,
     "status": "ok",
     "timestamp": 1659601294727,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "mPAO4BLJfGpr",
    "outputId": "c7c6f614-c3e0-4a64-d588-d4959da855c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "g_model = get_generator_model()\n",
    "# g_model.summary()\n",
    "# g_model = tf.keras.models.load_model('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN Generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1659601294729,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "Snt6-2Uaedch"
   },
   "outputs": [],
   "source": [
    "class WINFOGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator,q_network, latent_dim):\n",
    "        super(WINFOGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.q_network = q_network\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "        self.q_loss_tracker = keras.metrics.Mean(name=\"q_loss\")\n",
    "        self.batch_size = batch_size\n",
    "        self.d_steps = 5\n",
    "        self.gp_weight = 100\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer,q_optimizer, d_loss_fn, g_loss_fn, q_loss_fn):\n",
    "        super(WINFOGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.q_optimizer = q_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.q_loss_fn = q_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images = data\n",
    "\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for i in range(self.d_steps):\n",
    "          random_latent_vectors = tf.random.normal(\n",
    "              shape=(batch_size, self.latent_dim)\n",
    "          )\n",
    "          indx = tf.random.uniform(shape=(batch_size,), minval=0, maxval=c_cat_dim, dtype=tf.int32)\n",
    "          labels = tf.one_hot(indx , c_cat_dim)\n",
    "\n",
    "          # Train the discriminator.\n",
    "          with tf.GradientTape() as tape:\n",
    "              self.discriminator.trainable = True\n",
    "              # Generate fake images from the latent vector\n",
    "              fake_images = self.generator([random_latent_vectors,labels], training=True)\n",
    "              # Get the logits for the fake images\n",
    "              fake_logits = self.discriminator(fake_images, training=True)\n",
    "              # Get the logits for the real images\n",
    "              real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "              # Calculate the discriminator loss using the fake and real image logits\n",
    "              d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
    "              # Calculate the gradient penalty\n",
    "              gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "              # Add the gradient penalty to the original discriminator loss\n",
    "              d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "          # Get the gradients w.r.t the discriminator loss\n",
    "          d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "          # Update the weights of the discriminator using the discriminator optimizer\n",
    "          self.d_optimizer.apply_gradients(\n",
    "              zip(d_gradient, self.discriminator.trainable_variables)\n",
    "          )\n",
    "\n",
    "         # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        indx = tf.random.uniform(shape=(batch_size,), minval=0, maxval=c_cat_dim, dtype=tf.int32)\n",
    "        labels = tf.one_hot(indx , c_cat_dim)\n",
    "        \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as qn_tape:\n",
    "            self.discriminator.trainable = False\n",
    "            \n",
    "            g_tape.watch(self.generator.trainable_variables)\n",
    "            qn_tape.watch(self.q_network.trainable_variables)\n",
    "            \n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator([random_latent_vectors,labels], training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            \n",
    "            cat_output = self.q_network(generated_images, training=True)\n",
    "            cat_loss = self.q_loss_fn(labels , cat_output)\n",
    "            \n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits) + cat_loss\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        qn_gradinet = qn_tape.gradient(cat_loss , self.q_network.trainable_variables)\n",
    "        self.q_optimizer.apply_gradients(\n",
    "            zip(qn_gradinet , self.q_network.trainable_variables))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        self.q_loss_tracker.update_state(cat_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "            \"q_loss\": self.q_loss_tracker.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1659601294730,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "93rW3kQxxhe6"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1659601294732,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "RRNnvrCngID7"
   },
   "outputs": [],
   "source": [
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Sample noise for the interpolation.\n",
    "        _noise = tf.random.normal(shape=(4, latent_dim))\n",
    "        _label = keras.utils.to_categorical([0,1,2,3], c_cat_dim)\n",
    "        _label = tf.cast(_label, tf.float32)\n",
    "\n",
    "        # Combine the noise and the labels and run inference with the generator.\n",
    "        fake_images = self.model.generator.predict([_noise, _label])\n",
    "        fake_images = fake_images * 0.5 + 0.5\n",
    "        fake_images *= 255.0\n",
    "        converted_images = fake_images.astype(np.uint8)\n",
    "        # converted_images = tf.image.resize(converted_images, (256, 256)).numpy().astype(np.uint8)\n",
    "\n",
    "        \n",
    "        for i in range(4):\n",
    "          plt.subplot(2,2,i+1)\n",
    "          plt.imshow(converted_images[i][:,:,0],cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1659601294733,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "Ogb1weVSilfK"
   },
   "outputs": [],
   "source": [
    "callback = GANMonitor(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1659601294734,
     "user": {
      "displayName": "Hamid Ravaee",
      "userId": "07826360331025809750"
     },
     "user_tz": -270
    },
    "id": "gkZWVou_ehBw"
   },
   "outputs": [],
   "source": [
    "info_gan = WINFOGAN(\n",
    "    discriminator=d_model, generator=g_model, q_network=q_network, latent_dim=latent_dim\n",
    ")\n",
    "info_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.5, beta_2=0.9),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003,beta_1=0.5, beta_2=0.9),\n",
    "    q_optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9),\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    "    q_loss_fn=keras.losses.CategoricalCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dse3Y3aTv-oB"
   },
   "outputs": [],
   "source": [
    "info_gan.fit(dataset, epochs=200 , callbacks=[callback])\n",
    "# cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdrkunAOKBsQ"
   },
   "outputs": [],
   "source": [
    "# info_gan.generator.save('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN Generator.h5')\n",
    "# info_gan.discriminator.save('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN Discriminator.h5')\n",
    "# info_gan.q_network.save('/content/drive/MyDrive/Ravaee/GTEX/GE W-InfoGAN q-net.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOnkCLtMoacu1ob4/+mYX90",
   "collapsed_sections": [],
   "name": "GE W-info_GAN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
